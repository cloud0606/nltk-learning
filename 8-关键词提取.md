# 关键词提取实验报告

## 1. 作业要求

> 使用Jieba实现TextRank算法的关键词计算，采用与TF-IDF实验相同的文本语料（或任选），并对比其与TF-IDF算法在计算结果上的差异，分析差异产生的原因，考虑各自适用的情形。  提交作业：包含文本、代码和简要的分析文档（以压缩包形式提交）， 压缩包命名格式：TextRank-学号姓名.rar

## 2. 实验过程

- 数据集，采用孙老师分享的搜狗文本语料中的 C000008 类别下的语料，总共有 1990 个文本，对 10 号文本进行关键词提取 

### 2.1 TFID

- 代码：[8-jieba_tfidf_textrank.py](./8-jieba_tfidf_textrank.py)

  输入数据为待分析的的 10 号文本，直接将整段文本拼接为一个大字符串。

  ```python
  sentence = ""
  filename = "sougou_C08_10.txt"
  pf = open(filename,"r")
  sentence = pf.read()
  ```

  使用 **jieba** 自带的 TFIDF 提取关键词方法，

  ```python
  keywords = jieba.analyse.extract_tags(sentence, topK=20, withWeight=True, allowPOS=('ns', 'n', 'vn', 'v'))
  #  topK=20输出前20个关键词，withWeight为是否一并返回关键词权重值，allowPOS仅包括指定词性的词，
  ```

  提取结果：

  ```bash
  ('支付', 0.3857171291138667)  
  ('用户', 0.2577326960692)     
  ('网络', 0.19318374613844447) 
  ('平台', 0.16651574628133337) 
  ('交易', 0.13098285733866669) 
  ('客户', 0.10853388650026667) 
  ('账户', 0.08849797379333334) 
  ('工具', 0.06797170706266667) 
  ('预付费', 0.056898068281333335
  ('点卡', 0.056898068281333335)
  ('市值', 0.05550945452764444) 
  ('公司', 0.054498421344577774)
  ('邮件地址', 0.05313230001288888
  ('VISA卡', 0.0531323000128888
  ('增值', 0.0507273900828)     
  ('应用', 0.050677452927644445)
  ('注册', 0.04860885605873333) 
  ('营销', 0.048065569163733335)
  ('手机号码', 0.04697099174133333
  ('信用', 0.04489093183373334) 
  ```


基于之前的作业，使用 sougou 的 1990 个文本构建 TF-IDF 字典进行关键字提取。

- 代码：[8-jieba_tfidf_construct_idf_using_sougou_corpus.py](./8-jieba_tfidf_construct_idf_using_sougou_corpus.py)

- 首先遍历每个文本，构建文本及其分词后的词项列表二维矩阵。

  ```python
  dirname1 = r"D:\github\nltk-learning\code\sougou\C0000"+sc+"\\"
  files = os.listdir(dirname1)
  fm=0
  for fn in files:
          try:
                  f = codecs.open(dirname1+fn,mode='r')
                  text = f.readlines()
                  f.close()
                  voca=[]
                  for t in text:
                          words = re.sub(r'[\r\t\n\u3000]','',t)
                          words = list(jieba.cut(words))
                          words = [w for w in words if (w not in stopwords) and (len(w) > 0) and (re.search(r'^\D',w))]
                          voca = voca + words
                          terms[m:m+len(words)] = words
                          m = m + len(words)
                  documents.append(' '.join(voca))
                  textnames.append(dirname1 + fn)
                  fm += 1
          except:
                  continue
          if fm > 1000:
                  break
  ```

- 计算 TFIDF 值

  ```python
  vectorizer = CountVectorizer(min_df=10, token_pattern='(?u)\\b\\w+\\b')  # 定义计数器  
  tf = vectorizer.fit_transform(documents)  # 计算TF
  
  transformer = TfidfTransformer()  # 该类会统计每个词语的tf-idf权值
  tfidf = transformer.fit_transform(tf)  # fit_transform计算tf-idf，fit_transform将文本转为词频矩阵 
  
  word = vectorizer.get_feature_names() #获取词袋模型中的所有词语
  tfidf_val = tfidf.toarray() # 转为矩阵便于获取值
  ```

- 按照 TFIDF 降序排列输出关键词

  ```python
  worddic = {}
  for i in range(len(documents[0])):
          worddic[word[i]] = tfidf_val[0][i]
  keywords = sorted(worddic, key=lambda x:worddic[x], reverse=True)
  print(keywords)
  for i in range(len(keywords))[:30]:
          print(keywords[i],worddic[keywords[i]])
  ```

- 结果

  ```bash
  支付 0.3830572086985786   
  快 0.36710328890556304   
  的 0.34326156269378877   
  用户 0.2876060823469918   
  网络 0.18347479958227278  
  平台 0.16805766829766852  
  是 0.14081045495989822   
  交易 0.13210980742971593  
  客户 0.11071388482947837  
  一个 0.10637730509757867  
  工具 0.09384227188468906  
  第三方 0.09384227188468906 
  可以 0.0704582812055148   
  应用 0.0645936743044507   
  和 0.06409945526569369   
  市值 0.06272467447757994  
  我们 0.062254420013780065 
  在 0.06184858742045466   
  信用 0.0606086760034355   
  亿美元 0.06044428507820714 
  它 0.05743772956705998   
  他 0.05441780286571131   
  增值 0.05319332121113077  
  就 0.04828482576240469   
  美国 0.04811625396763155  
  注册 0.047863603210344316 
  做 0.04772008325142991   
  万 0.04731033553312988   
  因为 0.04683415995893396  
  机制 0.04652797444864196  
  ```

### 2.2 TextRank

- 读取数据将 10 号文本，直接将整段文本拼接为一个大字符串。

- 使用 **jieba** 自带的 TextRank 提取关键词方法

  ```python
  keywords = jieba.analyse.textrank(sentence, topK=20, withWeight=True, allowPOS=('ns', 'n', 'vn', 'v')) 
  ```

- 结果

  ```
  ('支付', 1.0)                 
  ('用户', 0.5420105859457008)  
  ('网络', 0.46837428353945815) 
  ('交易', 0.4673595970204522)  
  ('平台', 0.398001529964537)   
  ('账户', 0.27584014890711694) 
  ('客户', 0.24993887179244834) 
  ('中国', 0.21656539583988063) 
  ('公司', 0.20405496345586457) 
  ('美国', 0.182904689999771)   
  ('需要', 0.18191562573981176) 
  ('工具', 0.16840032391559914) 
  ('应用', 0.16138222379463157) 
  ('问题', 0.15105835981853247) 
  ('进行', 0.14524062984991326) 
  ('收入', 0.14493014443197666) 
  ('服务', 0.13835335068004215) 
  ('机制', 0.13729012992090284) 
  ('营销', 0.13194690705742565) 
  ('信用', 0.1292721182634932)  
  ```

## 3. 结果分析

**jieba 自带 TFIDF、TextRank提取出的关键词**

|        | jieba 自带 TFIDF                                             | jieba 自带 TextRank                                          |
| ------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 关键词 | ('支付', 0.3857171291138667)  <br/>('用户', 0.2577326960692)     <br/>('网络', 0.19318374613844447) <br/>('平台', 0.16651574628133337) <br/>('交易', 0.13098285733866669) <br/>('客户', 0.10853388650026667) <br/>('账户', 0.08849797379333334) <br/>('工具', 0.06797170706266667) <br/>('预付费', 0.056898068281333335<br/>('点卡', 0.056898068281333335)<br/>('市值', 0.05550945452764444) <br/>('公司', 0.054498421344577774)<br/>('邮件地址', 0.05313230001288888<br/>('VISA卡', 0.0531323000128888<br/>('增值', 0.0507273900828)     <br/>('应用', 0.050677452927644445)<br/>('注册', 0.04860885605873333) <br/>('营销', 0.048065569163733335)<br/>('手机号码', 0.04697099174133333<br/>('信用', 0.04489093183373334) | ('支付', 1.0)                 <br/>('用户', 0.5420105859457008)  <br/>('网络', 0.46837428353945815) <br/>('交易', 0.4673595970204522)  <br/>('平台', 0.398001529964537)   <br/>('账户', 0.27584014890711694) <br/>('客户', 0.24993887179244834) <br/>('中国', 0.21656539583988063) <br/>('公司', 0.20405496345586457) <br/>('美国', 0.182904689999771)   <br/>('需要', 0.18191562573981176) <br/>('工具', 0.16840032391559914) <br/>('应用', 0.16138222379463157) <br/>('问题', 0.15105835981853247) <br/>('进行', 0.14524062984991326) <br/>('收入', 0.14493014443197666) <br/>('服务', 0.13835335068004215) <br/>('机制', 0.13729012992090284) <br/>('营销', 0.13194690705742565) <br/>('信用', 0.1292721182634932) |
| 时间   | 1.0132231712341309 s                                         | 0.11070942878723145 s                                        |

- 从本次实验结果来看
  - 从提取出的关键词来看，两种算法提取出的关键词基本是一致的，而且关键词中没有出现与主题相去甚远的情况。因为两种方法都依赖于分词的效果，在此处由于分词的算法、停用词、关键词的词性等参数都保持一致，所以在关键词也很相似。
  - 从关键词的权值来看，TextRank 由于算法原理的，会有存在权值为 1 的 关键词，其它关键词权值就递减。TFIDF 是将 TF 值和 IDF 值（与语料库中其它文档有关系）相乘，所以权值没有什么特点。
  - 从模型的花费时间来看，按照原理，由于 TextRank 涉及到构建词图及迭代计算，所以提取速度较慢。但从该文本的模型构建时间来看，TextRank 反而优于 TFIDF，可能是由于文本长度较小导致。
- 适用场景
  - TF-IDF 需要有语料库的支撑，算法简单快速，**结果比较符合实际情况**。适用于**信息检索领域**，可以提前花时间建立信息索引，对于每个搜索的关键词计算每个文档的 TF-IDF 值，根据权值大小展示搜索结果。
  - TextRank **适用于脱离语料库的背景**，仅对单篇文档进行分析就可以提取该文档的关键词。可以用于**文档做自动摘要**，在句子维度进行关键程度打分，挑选关键句作为摘要。

**TFIDF 采用不同的 IDF 字典结果对比**

|        | jieba 自带 TFIDF                                             | sklearn 自带 TFIDF，使用 sougou 语料构建 tfidf 字典          |
| ------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 关键词 | ('支付', 0.3857171291138667)  <br/>('用户', 0.2577326960692)     <br/>('网络', 0.19318374613844447) <br/>('平台', 0.16651574628133337) <br/>('交易', 0.13098285733866669) <br/>('客户', 0.10853388650026667) <br/>('账户', 0.08849797379333334) <br/>('工具', 0.06797170706266667) <br/>('预付费', 0.056898068281333335<br/>('点卡', 0.056898068281333335)<br/>('市值', 0.05550945452764444) <br/>('公司', 0.054498421344577774)<br/>('邮件地址', 0.05313230001288888<br/>('VISA卡', 0.0531323000128888<br/>('增值', 0.0507273900828)     <br/>('应用', 0.050677452927644445)<br/>('注册', 0.04860885605873333) <br/>('营销', 0.048065569163733335)<br/>('手机号码', 0.04697099174133333<br/>('信用', 0.04489093183373334) | 支付 0.3830572086985786   <br/>快 0.36710328890556304   <br/>的 0.34326156269378877   <br/>用户 0.2876060823469918   <br/>网络 0.18347479958227278  <br/>平台 0.16805766829766852  <br/>是 0.14081045495989822   <br/>交易 0.13210980742971593  <br/>客户 0.11071388482947837  <br/>一个 0.10637730509757867  <br/>工具 0.09384227188468906  <br/>第三方 0.09384227188468906 <br/>可以 0.0704582812055148   <br/>应用 0.0645936743044507   <br/>和 0.06409945526569369   <br/>市值 0.06272467447757994  <br/>我们 0.062254420013780065 <br/>在 0.06184858742045466   <br/>信用 0.0606086760034355   <br/>亿美元 0.06044428507820714 <br/> |
| 时间   | 1.0132231712341309 s                                         | 0.598430871963501 s                                          |

- 从关键词的提取效果上来看，使用 souguo  语料库（右侧） 构建的模型关键词提取性能较差，两种方法分词方法是一致的，主要原因应该是在提取关键词时没有对词性进行筛选。 肉眼比对去掉 `快` 、`的` 、`是` 这样的词后，可以发现关键词还是一致的。

  因此，我们在做关键词提取时词性的筛选也时很重要的。

## 参考

- https://my.oschina.net/u/3800567/blog/2870640

